{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get tweets from Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code from: https://stackabuse.com/accessing-the-twitter-api-with-python/#disqus_thread\n",
    "\n",
    "# Import the Twython class\n",
    "from twython import Twython\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load credentials from json file\n",
    "with open(\"twitter_credentials.json\", \"r\") as file:\n",
    "    creds = json.load(file)\n",
    "\n",
    "# Instantiate an object\n",
    "python_tweets = Twython(creds['CONSUMER_KEY'], creds['CONSUMER_SECRET'])\n",
    "\n",
    "# Number of users\n",
    "Number_of_users = 50\n",
    "\n",
    "\n",
    "## QUERIES!\n",
    "## Create our queries\n",
    "\n",
    "query1 = {'q': 'climate',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query2 = {'q': 'businesses',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query3 = {'q': 'politics',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query4 = {'q': 'economy',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query5 = {'q': '#innovation',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query6 = {'q': 'nature',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query7 = {'q': 'culture',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query8 = {'q': 'healthcare',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query9 = {'q': 'pop culture',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query10 = {'q': 'culture',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "query11 = {'q': 'democrats',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "query12 = {'q': 'technology',\n",
    "        'result_type': 'mixed',\n",
    "        'count': 100,\n",
    "        'lang': 'en',\n",
    "        'tweet_mode' : 'extended',\n",
    "        }\n",
    "\n",
    "# Search tweets\n",
    "def search(query):\n",
    "    dict_ = {'user': [], 'date': [], 'hashtags': [], 'full_text': [], 'favorite_count': []}\n",
    "    for status in python_tweets.search(**query)['statuses']:\n",
    "        dict_['user'].append(status['user']['screen_name'])\n",
    "        dict_['date'].append(status['created_at'])\n",
    "        dict_['hashtags'].append([hashtag['text'] for hashtag in status['entities']['hashtags']])\n",
    "        dict_['full_text'].append(status['full_text'])\n",
    "        dict_['favorite_count'].append(status['favorite_count'])\n",
    "    return dict_\n",
    "\n",
    "# Note that these are the most popular tweets containing the word \"...\" in the past 7 days. \n",
    "\n",
    "\n",
    "df_q1 = pd.DataFrame(search(query1))\n",
    "df_q2 = pd.DataFrame(search(query2))\n",
    "df_q3 = pd.DataFrame(search(query3))\n",
    "df_q4 = pd.DataFrame(search(query4))\n",
    "df_q5 = pd.DataFrame(search(query5))\n",
    "df_q6 = pd.DataFrame(search(query6))\n",
    "df_q7 = pd.DataFrame(search(query7))\n",
    "df_q8 = pd.DataFrame(search(query8))\n",
    "df_q9 = pd.DataFrame(search(query9))\n",
    "df_q10 = pd.DataFrame(search(query10))\n",
    "df_q11 = pd.DataFrame(search(query11))\n",
    "df_q12 = pd.DataFrame(search(query12))\n",
    "\n",
    "\n",
    "df_total = pd.concat([df_q1,df_q2,df_q3,df_q4,df_q5,df_q6,df_q7,df_q8,df_q9,df_q10,df_q11,df_q12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model to identify topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:501: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    }
   ],
   "source": [
    "total_train_DF = pd.read_csv (r'train_data3.csv')\n",
    "start_train_DF = total_train_DF.drop(columns=['char_count','word_count','word_density','punctuation_count','title_word_count',\n",
    "                                              'upper_case_word_count','noun_count','verb_count','adj_count','adv_count',\n",
    "                                              'pron_count'])\n",
    "start_train_DF\n",
    "\n",
    "## Code from: \n",
    "## https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/\n",
    "\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "\n",
    "import pandas, xgboost, numpy, textblob, string\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "\n",
    "# split the dataset into training and validation datasets \n",
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(start_train_DF['full_text'], start_train_DF['label'])\n",
    "\n",
    "# label encode the target variable \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)\n",
    "\n",
    "## labels that are used\n",
    "topics = list(encoder.classes_)\n",
    "topics\n",
    "\n",
    "# create a count vectorizer object \n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(start_train_DF['full_text'])\n",
    "\n",
    "# transform the training and validation data using count vectorizer object\n",
    "xtrain_count =  count_vect.transform(train_x)\n",
    "xvalid_count =  count_vect.transform(valid_x)\n",
    "\n",
    "# word level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(start_train_DF['full_text'])\n",
    "xtrain_tfidf =  tfidf_vect.transform(train_x)\n",
    "xvalid_tfidf =  tfidf_vect.transform(valid_x)\n",
    "\n",
    "# ngram level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(start_train_DF['full_text'])\n",
    "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# characters level tf-idf\n",
    "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram_chars.fit(start_train_DF['full_text'])\n",
    "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) \n",
    "\n",
    "# load the pre-trained word-embedding vectors \n",
    "embeddings_index = {}\n",
    "for i, line in enumerate(open('data/glove.6B.300d.txt', encoding=\"utf8\")):\n",
    "    values = line.split()\n",
    "    embeddings_index[values[0]] = numpy.asarray(values[1:], dtype='float32')\n",
    "\n",
    "# create a tokenizer \n",
    "token = text.Tokenizer()\n",
    "token.fit_on_texts(start_train_DF['full_text'])\n",
    "word_index = token.word_index\n",
    "\n",
    "# convert text to sequence of tokens and pad them to ensure equal length vectors \n",
    "train_seq_x = sequence.pad_sequences(token.texts_to_sequences(train_x), maxlen=70)\n",
    "valid_seq_x = sequence.pad_sequences(token.texts_to_sequences(valid_x), maxlen=70)\n",
    "\n",
    "# create token-embedding mapping\n",
    "embedding_matrix = numpy.zeros((len(word_index) + 1, 300))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "start_train_DF['char_count'] = start_train_DF['full_text'].apply(len)\n",
    "start_train_DF['word_count'] = start_train_DF['full_text'].apply(lambda x: len(x.split()))\n",
    "start_train_DF['word_density'] = start_train_DF['char_count'] / (total_train_DF['word_count']+1)\n",
    "start_train_DF['punctuation_count'] = start_train_DF['full_text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "start_train_DF['title_word_count'] = start_train_DF['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "start_train_DF['upper_case_word_count'] = start_train_DF['full_text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "start_train_DF['noun_count'] = start_train_DF['full_text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "start_train_DF['verb_count'] = start_train_DF['full_text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "start_train_DF['adj_count'] = start_train_DF['full_text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "start_train_DF['adv_count'] = start_train_DF['full_text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "start_train_DF['pron_count'] = start_train_DF['full_text'].apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "\n",
    "\n",
    "# train a LDA Model\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "X_topics = lda_model.fit_transform(xtrain_count)\n",
    "topic_word = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "# view the topic models\n",
    "n_top_words = 10\n",
    "topic_summaries = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "    topic_summaries.append(' '.join(topic_words))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Train models\n",
    "\n",
    "# # Naive Bayes on Count Vectors\n",
    "# accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, train_y, xvalid_count)\n",
    "# print (\"NB, Count Vectors: \", accuracy)\n",
    "\n",
    "# # Naive Bayes on Word Level TF IDF Vectors\n",
    "# accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "# print (\"NB, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# # Naive Bayes on Ngram Level TF IDF Vectors\n",
    "# accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "# print (\"NB, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# # Naive Bayes on Character Level TF IDF Vectors\n",
    "# accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "# print (\"NB, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "# # Linear Classifier on Count Vectors\n",
    "# accuracy = train_model(linear_model.LogisticRegression(), xtrain_count, train_y, xvalid_count)\n",
    "# print (\"LR, Count Vectors: \", accuracy)\n",
    "\n",
    "# # Linear Classifier on Word Level TF IDF Vectors\n",
    "# accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "# print (\"LR, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# # Linear Classifier on Ngram Level TF IDF Vectors\n",
    "# accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "# print (\"LR, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# # Linear Classifier on Character Level TF IDF Vectors\n",
    "# accuracy = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram_chars, train_y, xvalid_tfidf_ngram_chars)\n",
    "# print (\"LR, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "# # SVM on Ngram Level TF IDF Vectors\n",
    "# accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, train_y, xvalid_tfidf_ngram)\n",
    "# print (\"SVM, N-Gram Vectors: \", accuracy)\n",
    "\n",
    "# # RF on Count Vectors\n",
    "# accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, train_y, xvalid_count)\n",
    "# print (\"RF, Count Vectors: \", accuracy)\n",
    "\n",
    "# # RF on Word Level TF IDF Vectors\n",
    "# accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, train_y, xvalid_tfidf)\n",
    "# print (\"RF, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# # Extereme Gradient Boosting on Count Vectors\n",
    "# accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y, xvalid_count.tocsc())\n",
    "# print (\"Xgb, Count Vectors: \", accuracy)\n",
    "\n",
    "# # Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
    "# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y, xvalid_tfidf.tocsc())\n",
    "# print (\"Xgb, WordLevel TF-IDF: \", accuracy)\n",
    "\n",
    "# # Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
    "# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y, xvalid_tfidf_ngram_chars.tocsc())\n",
    "# print (\"Xgb, CharLevel Vectors: \", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "# ## NB, Count Vectors:  0.7766666666666666\n",
    "# ## NB, WordLevel TF-IDF:  0.78\n",
    "# ## NB, N-Gram Vectors:  0.6233333333333333\n",
    "# ## NB, CharLevel Vectors:  0.7533333333333333\n",
    "# ## LR, Count Vectors:  0.8\n",
    "# ## LR, WordLevel TF-IDF:  0.8033333333333333\n",
    "# ## LR, N-Gram Vectors:  0.6266666666666667\n",
    "# ## LR, CharLevel Vectors:  0.8333333333333334\n",
    "# ## SVM, N-Gram Vectors:  0.5966666666666667\n",
    "# ## RF, Count Vectors:  0.7966666666666666\n",
    "# ## RF, WordLevel TF-IDF:  0.8033333333333333\n",
    "# ## [16:12:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "# ## C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
    "# ##   warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
    "# ## Xgb, Count Vectors:  0.77\n",
    "# ## [16:12:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "# ## Xgb, WordLevel TF-IDF:  0.77\n",
    "# ## [16:12:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
    "# ## Xgb, CharLevel Vectors:  0.8266666666666667"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### To save the AI model\n",
    "\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# model = ensemble.RandomForestClassifier()\n",
    "# model.fit(xtrain_tfidf, train_y)\n",
    "# # save the model to disk\n",
    "# filename = 'AImodel2.sav'\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = 'AImodel2.sav'\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_labelling(df):\n",
    "    ## Prepare data for input in the model\n",
    "    test_tfidf =  tfidf_vect.transform(df['full_text'])\n",
    "\n",
    "    ## Load data in model\n",
    "    result = loaded_model.predict(test_tfidf)\n",
    "\n",
    "    ## Get results\n",
    "    Final_result = []\n",
    "\n",
    "    for i in range(len(result)):\n",
    "        Final_result.append(topics[result[i]]) \n",
    "\n",
    "    # Final_result\n",
    "    df['topic'] = Final_result\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>full_text</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DonaldJTrumpJr</td>\n",
       "      <td>Wed Jun 09 21:39:33 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>I guess now that the entire world knows his so...</td>\n",
       "      <td>15877</td>\n",
       "      <td>climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chrislhayes</td>\n",
       "      <td>Wed Jun 09 18:30:53 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>An \"infrastructure bill\" that isn't climate-fo...</td>\n",
       "      <td>38390</td>\n",
       "      <td>climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LiZaOutlives</td>\n",
       "      <td>Thu Jun 10 12:33:48 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>Liza Minnelli has outlived the Keystone pipeli...</td>\n",
       "      <td>17491</td>\n",
       "      <td>climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sherrill4Moxy</td>\n",
       "      <td>Thu Jun 10 19:11:58 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @MrMichaelBurkes: Biden now says \"climate c...</td>\n",
       "      <td>0</td>\n",
       "      <td>climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GlobalUnion3</td>\n",
       "      <td>Thu Jun 10 19:11:57 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @ExtinctionR: Venezuela ðŸ‡»ðŸ‡ª is on the frontl...</td>\n",
       "      <td>0</td>\n",
       "      <td>climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>education_24x7</td>\n",
       "      <td>Thu Jun 10 19:10:51 +0000 2021</td>\n",
       "      <td>[Tech, NewsFlash]</td>\n",
       "      <td>RT @techinjektion: #Tech #NewsFlash 06/09\\nFac...</td>\n",
       "      <td>0</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RockymeOfficial</td>\n",
       "      <td>Thu Jun 10 19:10:50 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @OfficialJiasmin: Download in Qie app in Pl...</td>\n",
       "      <td>0</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>lae_lay</td>\n",
       "      <td>Thu Jun 10 19:10:49 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>After all these years and all this technology ...</td>\n",
       "      <td>0</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>anuragdubey777</td>\n",
       "      <td>Thu Jun 10 19:10:47 +0000 2021</td>\n",
       "      <td>[cloud]</td>\n",
       "      <td>RT @Omkar_Raii: Remote work infrastructure wit...</td>\n",
       "      <td>0</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>LitonDatta11</td>\n",
       "      <td>Thu Jun 10 19:10:45 +0000 2021</td>\n",
       "      <td>[]</td>\n",
       "      <td>RT @KiviuToken: The best video sharing platfor...</td>\n",
       "      <td>0</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1200 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               user                            date           hashtags  \\\n",
       "0    DonaldJTrumpJr  Wed Jun 09 21:39:33 +0000 2021                 []   \n",
       "1       chrislhayes  Wed Jun 09 18:30:53 +0000 2021                 []   \n",
       "2      LiZaOutlives  Thu Jun 10 12:33:48 +0000 2021                 []   \n",
       "3     Sherrill4Moxy  Thu Jun 10 19:11:58 +0000 2021                 []   \n",
       "4      GlobalUnion3  Thu Jun 10 19:11:57 +0000 2021                 []   \n",
       "..              ...                             ...                ...   \n",
       "95   education_24x7  Thu Jun 10 19:10:51 +0000 2021  [Tech, NewsFlash]   \n",
       "96  RockymeOfficial  Thu Jun 10 19:10:50 +0000 2021                 []   \n",
       "97          lae_lay  Thu Jun 10 19:10:49 +0000 2021                 []   \n",
       "98   anuragdubey777  Thu Jun 10 19:10:47 +0000 2021            [cloud]   \n",
       "99     LitonDatta11  Thu Jun 10 19:10:45 +0000 2021                 []   \n",
       "\n",
       "                                            full_text  favorite_count  \\\n",
       "0   I guess now that the entire world knows his so...           15877   \n",
       "1   An \"infrastructure bill\" that isn't climate-fo...           38390   \n",
       "2   Liza Minnelli has outlived the Keystone pipeli...           17491   \n",
       "3   RT @MrMichaelBurkes: Biden now says \"climate c...               0   \n",
       "4   RT @ExtinctionR: Venezuela ðŸ‡»ðŸ‡ª is on the frontl...               0   \n",
       "..                                                ...             ...   \n",
       "95  RT @techinjektion: #Tech #NewsFlash 06/09\\nFac...               0   \n",
       "96  RT @OfficialJiasmin: Download in Qie app in Pl...               0   \n",
       "97  After all these years and all this technology ...               0   \n",
       "98  RT @Omkar_Raii: Remote work infrastructure wit...               0   \n",
       "99  RT @KiviuToken: The best video sharing platfor...               0   \n",
       "\n",
       "       topic  \n",
       "0    climate  \n",
       "1    climate  \n",
       "2    climate  \n",
       "3    climate  \n",
       "4    climate  \n",
       "..       ...  \n",
       "95  politics  \n",
       "96   culture  \n",
       "97      tech  \n",
       "98      tech  \n",
       "99      tech  \n",
       "\n",
       "[1200 rows x 6 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_labelling(df_q1)\n",
    "topic_labelling(df_q2)\n",
    "topic_labelling(df_q3)\n",
    "topic_labelling(df_q4)\n",
    "topic_labelling(df_q5)\n",
    "topic_labelling(df_q6)\n",
    "topic_labelling(df_q7)\n",
    "topic_labelling(df_q8)\n",
    "topic_labelling(df_q9)\n",
    "topic_labelling(df_q10)\n",
    "topic_labelling(df_q11)\n",
    "topic_labelling(df_q12)\n",
    "topic_labelling(df_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fake user profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_q1.iloc[:20, :]\n",
    "df2 = df_q1.iloc[20:40, :]\n",
    "df3 = df_q1.iloc[40:60, :]\n",
    "df4 = df_q1.iloc[60:80, :]\n",
    "df5 = df_q1.iloc[80:, :]\n",
    "\n",
    "df6 = df_q2.iloc[:20, :]\n",
    "df7 = df_q2.iloc[20:40, :]\n",
    "df8 = df_q2.iloc[40:60, :]\n",
    "df9 = df_q2.iloc[60:80, :]\n",
    "df10 = df_q2.iloc[80:, :]\n",
    "\n",
    "df11 = df_q3.iloc[:20, :]\n",
    "df12 = df_q3.iloc[20:40, :]\n",
    "df13 = df_q3.iloc[40:60, :]\n",
    "df14 = df_q3.iloc[60:80, :]\n",
    "df15 = df_q3.iloc[80:, :]\n",
    "\n",
    "df16 = df_q4.iloc[:20, :]\n",
    "df17 = df_q4.iloc[20:40, :]\n",
    "df18 = df_q4.iloc[40:60, :]\n",
    "df19 = df_q4.iloc[60:80, :]\n",
    "df20 = df_q4.iloc[80:, :]\n",
    "\n",
    "df21 = df_q5.iloc[:20, :]\n",
    "df22 = df_q5.iloc[20:40, :]\n",
    "df23 = df_q5.iloc[40:60, :]\n",
    "df24 = df_q5.iloc[60:80, :]\n",
    "df25 = df_q5.iloc[80:, :]\n",
    "\n",
    "df26 = df_q6.iloc[:20, :]\n",
    "df27 = df_q6.iloc[20:40, :]\n",
    "df28 = df_q6.iloc[40:60, :]\n",
    "df29 = df_q6.iloc[60:80, :]\n",
    "df30 = df_q6.iloc[80:, :]\n",
    "\n",
    "df31 = df_q7.iloc[:20, :]\n",
    "df32 = df_q7.iloc[20:40, :]\n",
    "df33 = df_q7.iloc[40:60, :]\n",
    "df34 = df_q7.iloc[60:80, :]\n",
    "df35 = df_q7.iloc[80:, :]\n",
    "\n",
    "df36 = df_q8.iloc[:20, :]\n",
    "df37 = df_q8.iloc[20:40, :]\n",
    "df38 = df_q8.iloc[40:60, :]\n",
    "df39 = df_q8.iloc[60:80, :]\n",
    "df40 = df_q8.iloc[80:, :]\n",
    "\n",
    "df41 = df_q9.iloc[:20, :]\n",
    "df42 = df_q9.iloc[20:40, :]\n",
    "df43 = df_q9.iloc[40:60, :]\n",
    "df44 = df_q9.iloc[60:80, :]\n",
    "df45 = df_q9.iloc[80:, :]\n",
    "\n",
    "df46 = df_q10.iloc[:20, :]\n",
    "df47 = df_q10.iloc[20:40, :]\n",
    "df48 = df_q10.iloc[40:60, :]\n",
    "df49 = df_q10.iloc[60:80, :]\n",
    "df50 = df_q10.iloc[80:, :]\n",
    "\n",
    "df51 = df_q11.iloc[:20, :]\n",
    "df52 = df_q11.iloc[20:40, :]\n",
    "df53 = df_q11.iloc[40:60, :]\n",
    "df54 = df_q11.iloc[60:80, :]\n",
    "df55 = df_q11.iloc[80:, :]\n",
    "\n",
    "df56 = df_q12.iloc[:20, :]\n",
    "df57 = df_q12.iloc[20:40, :]\n",
    "df58 = df_q12.iloc[40:60, :]\n",
    "df59 = df_q12.iloc[60:80, :]\n",
    "df60 = df_q12.iloc[80:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of user: 50\n"
     ]
    }
   ],
   "source": [
    "import itertools \n",
    "\n",
    "numbers = []\n",
    "for i in range(1,61):\n",
    "    numbers.append(i)\n",
    "\n",
    "combinations = list(itertools.combinations(numbers, 5)) \n",
    "\n",
    "df_combinations = []\n",
    "x = 0\n",
    "\n",
    "for i in range(Number_of_users):\n",
    "\n",
    "    df_combinations.append(['df'+str(combinations[i+x][0]),\n",
    "                            'df'+str(combinations[i+x][1]),\n",
    "                            'df'+str(combinations[i+x][2]),\n",
    "                            'df'+str(combinations[i+x][3]),\n",
    "                            'df'+str(combinations[i+x][4])])\n",
    "    \n",
    "    name = 'user'+str(i)\n",
    "    globals()[name] = pd.concat([globals()[df_combinations[i][0]],\n",
    "                                 globals()[df_combinations[i][1]],\n",
    "                                 globals()[df_combinations[i][2]],\n",
    "                                 globals()[df_combinations[i][3]],\n",
    "                                 globals()[df_combinations[i][4]]])\n",
    "    x = x + 40000\n",
    "\n",
    "print('number of user:', len(df_combinations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF analyse and Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TF-IDF code from: https://www.youtube.com/watch?v=UvsQPsrZTK4\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re     ## Using regex to remove punctuation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "from nltk.tokenize import word_tokenize\n",
    "# nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_filter_tweets(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    \n",
    "    ## Lose stop words and tokenize the text\n",
    "    textfile = open('stopwords_extra.txt')\n",
    "    stopwords_extra = []\n",
    "    for line in textfile:\n",
    "        row_data = line.strip(\"\\n\").split()\n",
    "        for i, item in enumerate(row_data):\n",
    "            try:\n",
    "                row_data[i] = float(item)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            data_g = row_data[i].replace('[', '')\n",
    "        stopwords_extra.append(data_g)\n",
    "    stopwords_total = stopwords.union(set(stopwords_extra))\n",
    "    \n",
    "    BOW = word_tokenize(text)\n",
    "\n",
    "    filtered_list = []\n",
    "\n",
    "    for w in BOW:\n",
    "        if w not in stopwords_total:\n",
    "            filtered_list.append(w)\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    Lemma = []\n",
    "    for word in filtered_list:\n",
    "        Lemma.append(lemmatizer.lemmatize(word, pos =\"v\"))\n",
    "    \n",
    "    return Lemma\n",
    "\n",
    "\n",
    "def numofwords(Lemma, uniqueWords):\n",
    "    numofwords = dict.fromkeys(uniqueWords, 0)\n",
    "    for word in Lemma:\n",
    "        numofwords[word] += 1\n",
    "    return numofwords\n",
    "\n",
    "\n",
    "def computeTF(wordDict, bagOfWords):\n",
    "    tfDict = {}\n",
    "    bagOfWordsCount = len(bagOfWords)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count / float(bagOfWordsCount)\n",
    "    return tfDict\n",
    "\n",
    "\n",
    "def computeIDF(documents):\n",
    "    import math\n",
    "    N = len(documents)\n",
    "    \n",
    "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
    "    for document in documents:\n",
    "        for word, val in document.items():\n",
    "            if val > 0:\n",
    "                idfDict[word] += 1\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log(N / float(val))\n",
    "    return idfDict\n",
    "\n",
    "\n",
    "def computeTFIDF(tfBagOfwords, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBagOfwords.items():\n",
    "        tfidf[word] = val * idfs[word]\n",
    "    return tfidf\n",
    "\n",
    "\n",
    "def DF_user_profile(tfidf_s):\n",
    "    df = pd.DataFrame(tfidf_s)\n",
    "    top = df.apply(lambda s: s.abs().nlargest(20).index.tolist(), axis=1)\n",
    "    df_top = pd.DataFrame([top])\n",
    "#     df_top.columns = ['article1', 'article2', 'article3', 'article4', 'article5']\n",
    "\n",
    "#     df_1 = pd.DataFrame([df_top['article1']])\n",
    "\n",
    "    unnested_lst = []\n",
    "    for col in df_top.columns:\n",
    "        unnested_lst.append(df_top[col].apply(pd.Series).stack())\n",
    "    result = pd.concat(unnested_lst, axis=1, keys=df_top.columns)\n",
    "\n",
    "    result.reset_index(inplace=True)\n",
    "    result.drop('level_0', axis='columns', inplace=True)\n",
    "    result.drop('level_1', axis='columns', inplace=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def tfidf_short(tfidf):\n",
    "#     tfidf_short = dict(sorted(tfidf.items(), key=lambda item: item[1], reverse=True)[:20])\n",
    "    tfidf_short = dict(sorted(tfidf.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "    return tfidf_short\n",
    "\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return float(len(s1.intersection(s2)) / len(s1.union(s2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_analysis(user):\n",
    "    ## 1\n",
    "    list_user = user['full_text'].values.tolist()\n",
    "\n",
    "    ## 2\n",
    "    Lemma_user = []\n",
    "\n",
    "    for i in range(len(user)):\n",
    "        Lemma_user.append(Text_filter_tweets(list_user[i]))\n",
    "\n",
    "    ## 3\n",
    "    uniqueWords_user = []\n",
    "    lenght = []\n",
    "\n",
    "    for i in range(len(Lemma_user)):\n",
    "        lenght.append(len(Lemma_user[i]))\n",
    "        for a in range(len(Lemma_user[i])):\n",
    "            uniqueWords_user.append(Lemma_user[i][a])\n",
    "\n",
    "    ## 4\n",
    "    uniqueWords_user = set(uniqueWords_user)\n",
    "\n",
    "    ## 5\n",
    "    numofword_user = list(())\n",
    "    for i in range(len(Lemma_user)):\n",
    "        numofword_user.append(numofwords(Lemma_user[i], uniqueWords_user))\n",
    "    numofword_user = tuple(numofword_user)\n",
    "    # numofword_user\n",
    "\n",
    "    ## 6\n",
    "    tf_user = list(())\n",
    "    for i in range(len(Lemma_user)):\n",
    "        tf_user.append(computeTF(numofword_user[i], Lemma_user[i]))\n",
    "    tf_user = tuple(tf_user)\n",
    "    # tf_user\n",
    "\n",
    "    ## 7\n",
    "    idfs_user = computeIDF(numofword_user)\n",
    "    # idfs_user\n",
    "\n",
    "    ## 8\n",
    "    tfidf_user = list(())\n",
    "    for i in range(len(tf_user)):\n",
    "        tfidf_user.append(computeTF(tf_user[i], idfs_user))\n",
    "    tfidf_user = tuple(tfidf_user)\n",
    "    # tfidf_user\n",
    "\n",
    "    ## 9\n",
    "    for i in range(len(tfidf_user)):\n",
    "        user_profile_user = {**tfidf_user[i]}\n",
    "    # user_profile_user\n",
    "\n",
    "    ## 10\n",
    "    DF_user_profile(tfidf_user)\n",
    "    \n",
    "    return user_profile_user, tfidf_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numb_simularity():\n",
    "    numbers_similarity = []\n",
    "\n",
    "    for i in range(Number_of_users):\n",
    "        numbers_similarity.append(i)\n",
    "        # numbers_similarity\n",
    "\n",
    "    combinations_similarity = list(itertools.combinations(numbers_similarity, 2))\n",
    "    \n",
    "    return combinations_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simularity_calculation(topic):\n",
    "    for i in range(len(df_combinations)):\n",
    "        name = 'user'+str(i)\n",
    "        profile = 'user_profile'+str(i)\n",
    "        tfidf_profile = 'tfidf_user'+str(i)\n",
    "        values_returned = TFIDF_analysis(globals()[name][globals()[name]['topic'] == topic])\n",
    "        globals()[profile] = values_returned[0]\n",
    "        globals()[tfidf_profile] = values_returned[1]\n",
    "    \n",
    "#     numbers_similarity = []\n",
    "\n",
    "#     for i in range(Number_of_users):\n",
    "#         numbers_similarity.append(i)\n",
    "#     # numbers_similarity\n",
    "\n",
    "#     combinations_similarity = list(itertools.combinations(numbers_similarity, 2))\n",
    "#     # combinations_similarity\n",
    "    \n",
    "    combinations_similarity = numb_simularity()\n",
    "    \n",
    "    m_dict = {}\n",
    "\n",
    "    for i in range(len(combinations_similarity)):\n",
    "        c = combinations_similarity[i]\n",
    "        profile_A = 'user_profile'+str(combinations_similarity[i][0])\n",
    "        profile_B = 'user_profile'+str(combinations_similarity[i][1])\n",
    "        c_dict = {c: [jaccard_similarity(globals()[profile_A], globals()[profile_B])]}\n",
    "        m_dict = {**m_dict, **c_dict}\n",
    "    #     m_dict[globals()['profile_B']].append(jaccard_similarity(globals()[profile_A], globals()[profile_B]))\n",
    "    \n",
    "    return m_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def materix(m_dict):\n",
    "        \n",
    "    df_d = pd.DataFrame(m_dict)\n",
    "    df_m = df_d[0]\n",
    "\n",
    "    for i in range(Number_of_users-1):\n",
    "        df_m = df_m.append(df_d[i])\n",
    "\n",
    "    df_m = df_m.reset_index()\n",
    "    df_m = df_m.drop([0], axis=0)\n",
    "    df_m = df_m.reset_index()\n",
    "    del df_m['index']\n",
    "    del df_m['level_0']\n",
    "    \n",
    "    return df_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if the code crashes here, than try another twitter query that is related to the topics\n",
    "\n",
    "m_dict_politics = simularity_calculation('politics')\n",
    "df_m_politics = materix(m_dict_politics)\n",
    "\n",
    "m_dict_climate = simularity_calculation('climate')\n",
    "df_m_climate = materix(m_dict_climate)\n",
    "\n",
    "m_dict_technology = simularity_calculation('tech')\n",
    "df_m_technology = materix(m_dict_technology)\n",
    "\n",
    "m_dict_culture = simularity_calculation('culture')\n",
    "df_m_culture = materix(m_dict_culture)\n",
    "\n",
    "m_dict_health = simularity_calculation('health')\n",
    "df_m_health = materix(m_dict_health)\n",
    "\n",
    "m_dict_business = simularity_calculation('business')\n",
    "df_m_business = materix(m_dict_business)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_m_politics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting(m_dict, User_id):\n",
    "    User_sim_list = []\n",
    "    \n",
    "    combinations_similarity = numb_simularity()\n",
    "\n",
    "    for i in range(len(m_dict)):\n",
    "            if combinations_similarity[i][0] is User_id:\n",
    "                    User_sim_list.append([combinations_similarity[i][1], m_dict[combinations_similarity[i]]])\n",
    "            elif combinations_similarity[i][1] is User_id:\n",
    "                    User_sim_list.append([combinations_similarity[i][0], m_dict[combinations_similarity[i]]])\n",
    "\n",
    "    User_sim_list.sort(key=lambda x:x[1])\n",
    "    \n",
    "    return User_sim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapp(user_sim_lists):\n",
    "    Map_right = []\n",
    "    Map_left = []\n",
    "\n",
    "    for i in range(len(user_sim_lists)):\n",
    "        if (i % 2 == 0): \n",
    "            Map_right.append(user_sim_lists[i])\n",
    "        else: \n",
    "            Map_left.append(user_sim_lists[i])\n",
    "\n",
    "    # print('Left:', Map_left, '\\n', '\\n', 'Right:', Map_right)\n",
    "    \n",
    "    Mapping_list = []\n",
    "\n",
    "    for i in range(len(Map_left)):\n",
    "        Mapping_list.append(Map_left[i][0])\n",
    "       \n",
    "    Mapping_list.append(User_id)\n",
    "        \n",
    "    for i in range(len(Map_right)):\n",
    "        Mapping_list.append(Map_right[len(Map_right)-1-i][0])\n",
    "\n",
    "    # Mapping_list\n",
    "    \n",
    "    def maprange( a, b, s):\n",
    "        (a1, a2), (b1, b2) = a, b\n",
    "        return  b1 + ((s - a1) * (b2 - b1) / (a2 - a1))\n",
    "\n",
    "    Mapped_list = []\n",
    "\n",
    "    for s in range(360):\n",
    "        Mapped_list.append(int(maprange( (0, 360), (0, len(Mapping_list)), s)))\n",
    "\n",
    "    # len(Mapped_list)\n",
    "    # Mapped_list\n",
    "    \n",
    "    Final_mapped = []\n",
    "\n",
    "    for i in range(len(Mapped_list)):\n",
    "        Final_mapped.append(Mapping_list[Mapped_list[i]])\n",
    "    \n",
    "    return Final_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_list_politics = []\n",
    "\n",
    "for i in range(Number_of_users):\n",
    "    sorted_list_politics.append(sorting(m_dict_politics, i))\n",
    "    \n",
    "    \n",
    "sorted_list_climate = []\n",
    "\n",
    "for i in range(Number_of_users):\n",
    "    sorted_list_climate.append(sorting(m_dict_climate, i))\n",
    "    \n",
    "    \n",
    "sorted_list_technology = []\n",
    "\n",
    "for i in range(Number_of_users):\n",
    "    sorted_list_technology.append(sorting(m_dict_technology, i))\n",
    "    \n",
    "    \n",
    "sorted_list_culture = []\n",
    "\n",
    "for i in range(Number_of_users):\n",
    "    sorted_list_culture.append(sorting(m_dict_culture, i))\n",
    "    \n",
    "    \n",
    "sorted_list_health = []\n",
    "\n",
    "for i in range(Number_of_users):\n",
    "    sorted_list_health.append(sorting(m_dict_health, i))\n",
    "    \n",
    "    \n",
    "sorted_list_business = []\n",
    "\n",
    "for i in range(Number_of_users):\n",
    "    sorted_list_business.append(sorting(m_dict_business, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connection to interface via OOCSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Jim_FBP_algorithm190]: connecting to oocsi.id.tue.nl port 4444\n",
      "[Jim_FBP_algorithm190]: connection established\n",
      "[Jim_FBP_algorithm190]: subscribed to popping_bubbles_interface\n",
      "45\n",
      "[40, 40, 40, 40, 40, 40, 40, 40, 34, 34, 34, 34, 34, 34, 34, 34, 29, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 31, 31, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 44, 44, 44, 44, 44, 44, 44, 44, 42, 42, 42, 42, 42, 42, 42, 42, 13, 13, 13, 13, 13, 13, 13, 13, 46, 46, 46, 46, 46, 46, 46, 46, 12, 12, 12, 12, 12, 12, 12, 12, 45, 45, 45, 45, 45, 45, 45, 45, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 26, 26, 26, 26, 26, 23, 23, 23, 23, 23, 23, 23, 23, 49, 49, 49, 49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 47, 47, 47, 43, 43, 43, 43, 43, 43, 43, 43, 22, 22, 22, 22, 22, 22, 22, 22, 28, 28, 28, 28, 28, 28, 28, 28, 33, 33, 33, 33, 33, 33, 33, 33, 19, 19, 19, 19, 19, 19, 19, 19, 25, 25, 25, 25, 25, 25, 25, 25, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 27, 27, 27, 27, 27, 27, 27, 27, 24, 24, 24, 24, 24, 24, 24, 24, 41, 41, 41, 41, 41, 41, 41, 41, 35, 35, 35, 35, 35, 35, 35, 35]\n",
      "[43, 43, 43, 43, 43, 43, 43, 43, 30, 30, 30, 30, 30, 30, 30, 30, 49, 49, 49, 49, 49, 49, 49, 49, 37, 37, 37, 37, 37, 37, 37, 37, 28, 28, 28, 28, 28, 28, 28, 28, 31, 31, 31, 31, 31, 31, 31, 31, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 16, 16, 16, 16, 16, 21, 21, 21, 21, 21, 21, 21, 21, 40, 40, 40, 40, 40, 40, 40, 40, 23, 23, 23, 23, 23, 23, 23, 23, 1, 1, 1, 1, 1, 1, 1, 1, 42, 42, 42, 42, 42, 42, 42, 42, 26, 26, 26, 26, 26, 26, 26, 26, 34, 34, 34, 34, 34, 34, 34, 34, 13, 13, 13, 13, 13, 13, 13, 13, 47, 47, 47, 47, 47, 47, 47, 47, 3, 3, 3, 3, 3, 3, 3, 3, 45, 45, 45, 45, 45, 45, 45, 45, 12, 12, 12, 12, 12, 12, 12, 12, 38, 38, 38, 38, 38, 38, 38, 38, 29, 29, 29, 29, 29, 29, 29, 29, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 44, 44, 44, 44, 44, 44, 44, 44, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 27, 27, 27, 27, 27, 27, 27, 27, 22, 22, 22, 22, 22, 22, 22, 22, 18, 18, 18, 18, 18, 18, 18, 18, 33, 33, 33, 33, 33, 33, 33, 33, 46, 46, 46, 46, 46, 46, 46, 46, 9, 9, 9, 9, 9, 9, 9, 9, 35, 35, 35, 35, 35, 35, 35, 35, 32, 32, 32, 32, 32, 32, 32, 32, 14, 14, 14, 14, 14, 14, 14, 14, 25, 25, 25, 25, 25, 25, 25, 25, 4, 4, 4, 4, 4, 4, 4, 4, 39, 39, 39, 39, 39, 39, 39, 39, 15, 15, 15, 15, 15, 15, 15, 15, 41, 41, 41, 41, 41, 41, 41, 41, 17, 17, 17, 17, 17, 17, 17, 17, 11, 11, 11, 11, 11, 11, 11, 11, 48, 48, 48, 48, 48, 48, 48, 48, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "user22\n",
      "45\n",
      "[40, 40, 40, 40, 40, 40, 40, 40, 34, 34, 34, 34, 34, 34, 34, 34, 29, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 31, 31, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 44, 44, 44, 44, 44, 44, 44, 44, 42, 42, 42, 42, 42, 42, 42, 42, 13, 13, 13, 13, 13, 13, 13, 13, 46, 46, 46, 46, 46, 46, 46, 46, 12, 12, 12, 12, 12, 12, 12, 12, 45, 45, 45, 45, 45, 45, 45, 45, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 26, 26, 26, 26, 26, 23, 23, 23, 23, 23, 23, 23, 23, 49, 49, 49, 49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 47, 47, 47, 43, 43, 43, 43, 43, 43, 43, 43, 22, 22, 22, 22, 22, 22, 22, 22, 28, 28, 28, 28, 28, 28, 28, 28, 33, 33, 33, 33, 33, 33, 33, 33, 19, 19, 19, 19, 19, 19, 19, 19, 25, 25, 25, 25, 25, 25, 25, 25, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 27, 27, 27, 27, 27, 27, 27, 27, 24, 24, 24, 24, 24, 24, 24, 24, 41, 41, 41, 41, 41, 41, 41, 41, 35, 35, 35, 35, 35, 35, 35, 35]\n",
      "[43, 43, 43, 43, 43, 43, 43, 43, 30, 30, 30, 30, 30, 30, 30, 30, 49, 49, 49, 49, 49, 49, 49, 49, 37, 37, 37, 37, 37, 37, 37, 37, 28, 28, 28, 28, 28, 28, 28, 28, 31, 31, 31, 31, 31, 31, 31, 31, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 16, 16, 16, 16, 16, 21, 21, 21, 21, 21, 21, 21, 21, 40, 40, 40, 40, 40, 40, 40, 40, 23, 23, 23, 23, 23, 23, 23, 23, 1, 1, 1, 1, 1, 1, 1, 1, 42, 42, 42, 42, 42, 42, 42, 42, 26, 26, 26, 26, 26, 26, 26, 26, 34, 34, 34, 34, 34, 34, 34, 34, 13, 13, 13, 13, 13, 13, 13, 13, 47, 47, 47, 47, 47, 47, 47, 47, 3, 3, 3, 3, 3, 3, 3, 3, 45, 45, 45, 45, 45, 45, 45, 45, 12, 12, 12, 12, 12, 12, 12, 12, 38, 38, 38, 38, 38, 38, 38, 38, 29, 29, 29, 29, 29, 29, 29, 29, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 44, 44, 44, 44, 44, 44, 44, 44, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 27, 27, 27, 27, 27, 27, 27, 27, 22, 22, 22, 22, 22, 22, 22, 22, 18, 18, 18, 18, 18, 18, 18, 18, 33, 33, 33, 33, 33, 33, 33, 33, 46, 46, 46, 46, 46, 46, 46, 46, 9, 9, 9, 9, 9, 9, 9, 9, 35, 35, 35, 35, 35, 35, 35, 35, 32, 32, 32, 32, 32, 32, 32, 32, 14, 14, 14, 14, 14, 14, 14, 14, 25, 25, 25, 25, 25, 25, 25, 25, 4, 4, 4, 4, 4, 4, 4, 4, 39, 39, 39, 39, 39, 39, 39, 39, 15, 15, 15, 15, 15, 15, 15, 15, 41, 41, 41, 41, 41, 41, 41, 41, 17, 17, 17, 17, 17, 17, 17, 17, 11, 11, 11, 11, 11, 11, 11, 11, 48, 48, 48, 48, 48, 48, 48, 48, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "user22\n",
      "45\n",
      "[40, 40, 40, 40, 40, 40, 40, 40, 34, 34, 34, 34, 34, 34, 34, 34, 29, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 31, 31, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 44, 44, 44, 44, 44, 44, 44, 44, 42, 42, 42, 42, 42, 42, 42, 42, 13, 13, 13, 13, 13, 13, 13, 13, 46, 46, 46, 46, 46, 46, 46, 46, 12, 12, 12, 12, 12, 12, 12, 12, 45, 45, 45, 45, 45, 45, 45, 45, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 26, 26, 26, 26, 26, 23, 23, 23, 23, 23, 23, 23, 23, 49, 49, 49, 49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 47, 47, 47, 43, 43, 43, 43, 43, 43, 43, 43, 22, 22, 22, 22, 22, 22, 22, 22, 28, 28, 28, 28, 28, 28, 28, 28, 33, 33, 33, 33, 33, 33, 33, 33, 19, 19, 19, 19, 19, 19, 19, 19, 25, 25, 25, 25, 25, 25, 25, 25, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 27, 27, 27, 27, 27, 27, 27, 27, 24, 24, 24, 24, 24, 24, 24, 24, 41, 41, 41, 41, 41, 41, 41, 41, 35, 35, 35, 35, 35, 35, 35, 35]\n",
      "[43, 43, 43, 43, 43, 43, 43, 43, 30, 30, 30, 30, 30, 30, 30, 30, 49, 49, 49, 49, 49, 49, 49, 49, 37, 37, 37, 37, 37, 37, 37, 37, 28, 28, 28, 28, 28, 28, 28, 28, 31, 31, 31, 31, 31, 31, 31, 31, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 16, 16, 16, 16, 16, 21, 21, 21, 21, 21, 21, 21, 21, 40, 40, 40, 40, 40, 40, 40, 40, 23, 23, 23, 23, 23, 23, 23, 23, 1, 1, 1, 1, 1, 1, 1, 1, 42, 42, 42, 42, 42, 42, 42, 42, 26, 26, 26, 26, 26, 26, 26, 26, 34, 34, 34, 34, 34, 34, 34, 34, 13, 13, 13, 13, 13, 13, 13, 13, 47, 47, 47, 47, 47, 47, 47, 47, 3, 3, 3, 3, 3, 3, 3, 3, 45, 45, 45, 45, 45, 45, 45, 45, 12, 12, 12, 12, 12, 12, 12, 12, 38, 38, 38, 38, 38, 38, 38, 38, 29, 29, 29, 29, 29, 29, 29, 29, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 44, 44, 44, 44, 44, 44, 44, 44, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 27, 27, 27, 27, 27, 27, 27, 27, 22, 22, 22, 22, 22, 22, 22, 22, 18, 18, 18, 18, 18, 18, 18, 18, 33, 33, 33, 33, 33, 33, 33, 33, 46, 46, 46, 46, 46, 46, 46, 46, 9, 9, 9, 9, 9, 9, 9, 9, 35, 35, 35, 35, 35, 35, 35, 35, 32, 32, 32, 32, 32, 32, 32, 32, 14, 14, 14, 14, 14, 14, 14, 14, 25, 25, 25, 25, 25, 25, 25, 25, 4, 4, 4, 4, 4, 4, 4, 4, 39, 39, 39, 39, 39, 39, 39, 39, 15, 15, 15, 15, 15, 15, 15, 15, 41, 41, 41, 41, 41, 41, 41, 41, 17, 17, 17, 17, 17, 17, 17, 17, 11, 11, 11, 11, 11, 11, 11, 11, 48, 48, 48, 48, 48, 48, 48, 48, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user22\n",
      "45\n",
      "[40, 40, 40, 40, 40, 40, 40, 40, 34, 34, 34, 34, 34, 34, 34, 34, 29, 29, 29, 29, 29, 29, 29, 29, 31, 31, 31, 31, 31, 31, 31, 31, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21, 21, 21, 21, 21, 21, 30, 30, 30, 30, 30, 30, 30, 30, 15, 15, 15, 15, 15, 15, 15, 15, 14, 14, 14, 14, 14, 14, 14, 14, 16, 16, 16, 16, 16, 16, 16, 16, 32, 32, 32, 32, 32, 32, 32, 32, 44, 44, 44, 44, 44, 44, 44, 44, 42, 42, 42, 42, 42, 42, 42, 42, 13, 13, 13, 13, 13, 13, 13, 13, 46, 46, 46, 46, 46, 46, 46, 46, 12, 12, 12, 12, 12, 12, 12, 12, 45, 45, 45, 45, 45, 45, 45, 45, 1, 1, 1, 1, 1, 1, 1, 1, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 9, 9, 9, 9, 9, 9, 9, 9, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11, 11, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 26, 26, 26, 26, 26, 23, 23, 23, 23, 23, 23, 23, 23, 49, 49, 49, 49, 49, 49, 49, 49, 48, 48, 48, 48, 48, 48, 48, 48, 47, 47, 47, 47, 47, 47, 47, 47, 43, 43, 43, 43, 43, 43, 43, 43, 22, 22, 22, 22, 22, 22, 22, 22, 28, 28, 28, 28, 28, 28, 28, 28, 33, 33, 33, 33, 33, 33, 33, 33, 19, 19, 19, 19, 19, 19, 19, 19, 25, 25, 25, 25, 25, 25, 25, 25, 18, 18, 18, 18, 18, 18, 18, 18, 17, 17, 17, 17, 17, 17, 17, 17, 27, 27, 27, 27, 27, 27, 27, 27, 24, 24, 24, 24, 24, 24, 24, 24, 41, 41, 41, 41, 41, 41, 41, 41, 35, 35, 35, 35, 35, 35, 35, 35]\n",
      "[43, 43, 43, 43, 43, 43, 43, 43, 30, 30, 30, 30, 30, 30, 30, 30, 49, 49, 49, 49, 49, 49, 49, 49, 37, 37, 37, 37, 37, 37, 37, 37, 28, 28, 28, 28, 28, 28, 28, 28, 31, 31, 31, 31, 31, 31, 31, 31, 24, 24, 24, 24, 24, 24, 24, 24, 16, 16, 16, 16, 16, 16, 16, 16, 21, 21, 21, 21, 21, 21, 21, 21, 40, 40, 40, 40, 40, 40, 40, 40, 23, 23, 23, 23, 23, 23, 23, 23, 1, 1, 1, 1, 1, 1, 1, 1, 42, 42, 42, 42, 42, 42, 42, 42, 26, 26, 26, 26, 26, 26, 26, 26, 34, 34, 34, 34, 34, 34, 34, 34, 13, 13, 13, 13, 13, 13, 13, 13, 47, 47, 47, 47, 47, 47, 47, 47, 3, 3, 3, 3, 3, 3, 3, 3, 45, 45, 45, 45, 45, 45, 45, 45, 12, 12, 12, 12, 12, 12, 12, 12, 38, 38, 38, 38, 38, 38, 38, 38, 29, 29, 29, 29, 29, 29, 29, 29, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 44, 44, 44, 44, 44, 44, 44, 44, 6, 6, 6, 6, 6, 6, 6, 6, 10, 10, 10, 10, 10, 10, 10, 10, 27, 27, 27, 27, 27, 27, 27, 27, 22, 22, 22, 22, 22, 22, 22, 22, 18, 18, 18, 18, 18, 18, 18, 18, 33, 33, 33, 33, 33, 33, 33, 33, 46, 46, 46, 46, 46, 46, 46, 46, 9, 9, 9, 9, 9, 9, 9, 9, 35, 35, 35, 35, 35, 35, 35, 35, 32, 32, 32, 32, 32, 32, 32, 32, 14, 14, 14, 14, 14, 14, 14, 14, 25, 25, 25, 25, 25, 25, 25, 25, 4, 4, 4, 4, 4, 4, 4, 4, 39, 39, 39, 39, 39, 39, 39, 39, 15, 15, 15, 15, 15, 15, 15, 15, 41, 41, 41, 41, 41, 41, 41, 41, 17, 17, 17, 17, 17, 17, 17, 17, 11, 11, 11, 11, 11, 11, 11, 11, 48, 48, 48, 48, 48, 48, 48, 48, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "user22\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user39\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user3\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user3\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user3\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user49\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user49\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user49\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user49\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user49\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n",
      "user49\n",
      "5\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n",
      "[49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 49, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 33, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user49\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4ce59bcd1f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mUser_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_list3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_list3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;31m#         print(User_id)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mSelect_numb_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_list5\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_list5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Copyright (c) 2017 Mathias Funk\n",
    "# This software is released under the MIT License.\n",
    "# http://opensource.org/licenses/mit-license.php\n",
    "\n",
    "from oocsi import OOCSI\n",
    "import time\n",
    "from random import random\n",
    "import math\n",
    "import random\n",
    "\n",
    "\n",
    "check_list1 = [3.9741147067910885]\n",
    "check_list2 = [4]\n",
    "check_list3 = [7]\n",
    "check_list4 = ['business']\n",
    "check_list5 = [45,45,45,45]\n",
    "state = 1\n",
    "\n",
    "# User_sim_list1 = []\n",
    "# User_sim_list2 = []\n",
    "# User_sim_list3 = []\n",
    "# User_sim_list4 = []\n",
    "# User_sim_list5 = []\n",
    "\n",
    "def receiveEvent(sender, recipient, event):\n",
    "    check_list1[0] = event.get('rad_b')\n",
    "    check_list2.append(event.get('rad_s'))\n",
    "    check_list3.append(event.get('user'))\n",
    "    check_list4.append(event.get('topic'))\n",
    "    check_list5.append(event.get('numb_profiles'))\n",
    "\n",
    "## Change the number everytime you run the code\n",
    "o = OOCSI(\"Jim_FBP_algorithm190\", \"oocsi.id.tue.nl\")\n",
    "\n",
    "o.subscribe('popping_bubbles_interface', receiveEvent)\n",
    "\n",
    "while 1:   \n",
    "    if state == 1:\n",
    "        User_id = int(check_list3[(len(check_list3)-1)])\n",
    "#         print(User_id)\n",
    "        Select_numb_users = check_list5[(len(check_list5)-1)]\n",
    "        \n",
    "        User_sim_list_politics = sorted_list_politics[User_id]\n",
    "        User_sim_list_business = sorted_list_business[User_id]\n",
    "        User_sim_list_technology = sorted_list_technology[User_id]\n",
    "        User_sim_list_culture = sorted_list_culture[User_id]\n",
    "        User_sim_list_health = sorted_list_health[User_id]\n",
    "        User_sim_list_climate = sorted_list_climate[User_id]\n",
    "        \n",
    "        if len(User_sim_list_politics) == 0:\n",
    "            print('empty')\n",
    "        \n",
    "        Select_User_sim_list_politics = User_sim_list_politics[(len(User_sim_list_politics)-Select_numb_users):(len(User_sim_list_politics)-1)]\n",
    "        Select_User_sim_list_business = User_sim_list_business[(len(User_sim_list_business)-Select_numb_users):(len(User_sim_list_business)-1)]\n",
    "        Select_User_sim_list_technology = User_sim_list_technology[(len(User_sim_list_technology)-Select_numb_users):(len(User_sim_list_technology)-1)]\n",
    "        Select_User_sim_list_culture = User_sim_list_culture[(len(User_sim_list_culture)-Select_numb_users):(len(User_sim_list_culture)-1)]\n",
    "        Select_User_sim_list_health = User_sim_list_health[(len(User_sim_list_health)-Select_numb_users):(len(User_sim_list_health)-1)]\n",
    "        Select_User_sim_list_climate = User_sim_list_climate[(len(User_sim_list_climate)-Select_numb_users):(len(User_sim_list_climate)-1)]\n",
    "        \n",
    "        F_m_politics = mapp(Select_User_sim_list_politics)\n",
    "        F_m_business = mapp(Select_User_sim_list_business)\n",
    "        F_m_technology = mapp(Select_User_sim_list_technology)\n",
    "        F_m_culture = mapp(Select_User_sim_list_culture)\n",
    "        F_m_health = mapp(Select_User_sim_list_health)\n",
    "        F_m_climate = mapp(Select_User_sim_list_climate)\n",
    "\n",
    "        if (check_list4[(len(check_list4)-1)] == 'politics'):\n",
    "            Final_mapped = F_m_politics\n",
    "        elif (check_list4[(len(check_list4)-1)] == 'business'):\n",
    "            Final_mapped = F_m_business\n",
    "        elif (check_list4[(len(check_list4)-1)] == 'tech'):\n",
    "            Final_mapped = F_m_technology\n",
    "        elif (check_list4[(len(check_list4)-1)] == 'culture'):\n",
    "            Final_mapped = F_m_culture\n",
    "        elif (check_list4[(len(check_list4)-1)] == 'health'):\n",
    "            Final_mapped = F_m_health\n",
    "        elif (check_list4[(len(check_list4)-1)] == 'climate'):\n",
    "            Final_mapped = F_m_climate\n",
    "            \n",
    "        current_profile = Final_mapped[int(abs(math.degrees(check_list1[len(check_list1)-1])))]\n",
    "        n_p = 'user'+ str(current_profile)    \n",
    "        n_p_2 = globals()[n_p].loc[globals()[n_p]['topic'] == check_list4[(len(check_list4)-1)]]\n",
    "        n_p_3 = n_p_2.reset_index()\n",
    "        fav = n_p_3['favorite_count']\n",
    "        \n",
    "#         print(check_list5)\n",
    "        print(Select_numb_users)\n",
    "        print(F_m_climate)\n",
    "        print(Final_mapped)\n",
    "        \n",
    "        if (len(n_p_3) == 0):\n",
    "            state = 2\n",
    "        else:\n",
    "            state = 3\n",
    "    \n",
    "    elif state == 2:\n",
    "        current_profile = Final_mapped[int(abs(math.degrees(check_list1[len(check_list1)-1]))) + 1]\n",
    "        print(state)\n",
    "        state = 1\n",
    "        \n",
    "    elif state == 3:\n",
    "#         nn = random.randint(0,(len(n_p_3)-1))\n",
    "#         print(current_profile)\n",
    "\n",
    "        message = {}\n",
    "        message['start'] = int(333)\n",
    "        message['num_Users'] = Final_mapped[int(abs(math.degrees(check_list1[len(check_list1)-1])))]\n",
    "        message['text'] = n_p_3.iloc[fav.idxmax()]['full_text']\n",
    "        message['current_profile'] = n_p\n",
    "        \n",
    "        o.send('popping_bubbles_algorithm', message)\n",
    "        print(n_p)\n",
    "\n",
    "        state = 1\n",
    "   \n",
    "    # wait and continue\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
